selector_to_html = {"a[href=\"lectures/lecture-5.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Image Processing (Part 2) Fourier Domain<a class=\"headerlink\" href=\"#image-processing-part-2-fourier-domain\" title=\"Link to this heading\">#</a></h1><h2>What is a Function in the Time Domain?<a class=\"headerlink\" href=\"#what-is-a-function-in-the-time-domain\" title=\"Link to this heading\">#</a></h2><p><strong>Mathematically:</strong><br/>\n<span class=\"math notranslate nohighlight\">\\( f(t): \\mathbb{R} \\to \\mathbb{R} \\)</span> \u2014 maps time to amplitude.</p>", "a[href=\"#course-design-experience\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Course Design Experience<a class=\"headerlink\" href=\"#course-design-experience\" title=\"Link to this heading\">#</a></h2><p><strong>Overview:</strong><br/>\nThis was the first UB course to feature a full diffusion-model module, with all generative AI content built from scratch.</p>", "a[href=\"lectures/lecture-4.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Image Processing (Part 1) Spatial Domain<a class=\"headerlink\" href=\"#image-processing-part-1-spatial-domain\" title=\"Link to this heading\">#</a></h1><p>As we established multiple times in this course that images are nothing but <code class=\"docutils literal notranslate\"><span class=\"pre\">numpy</span> <span class=\"pre\">arrays</span></code> where each value in the grid represents a pixel. In the case of a grayscale image, the pixel represents intensity from <code class=\"docutils literal notranslate\"><span class=\"pre\">0</span> <span class=\"pre\">to</span> <span class=\"pre\">255</span></code> and in the case of a colored RGB image, each pixel is a vector <code class=\"docutils literal notranslate\"><span class=\"pre\">[R,</span> <span class=\"pre\">G,</span> <span class=\"pre\">B]</span></code> values ranging from 0 to 255. Depending on different combinations of R, G, and B, we can visualize different colors at each pixel.</p><p><em>In this lecture, we will look at various image processing techniques that will result in extraction of various features from images.</em></p>", "a[href=\"lectures/lecture-9.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Feature Detection and Extraction<a class=\"headerlink\" href=\"#feature-detection-and-extraction\" title=\"Link to this heading\">#</a></h1><p>In this chapter, we move from <strong>depth estimation</strong> to one of the core tasks in classical computer vision: <strong>finding good feature points</strong>.</p>", "a[href=\"#about-the-course\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">About the Course<a class=\"headerlink\" href=\"#about-the-course\" title=\"Link to this heading\">#</a></h2><p><strong>Overview:</strong><br/>\nA summer course that takes students from classical computer vision foundations all the way to modern generative models and practical systems.</p>", "a[href=\"lectures/lecture-1.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">What is a Pixel and what is an Image?<a class=\"headerlink\" href=\"#what-is-a-pixel-and-what-is-an-image\" title=\"Link to this heading\">#</a></h1><p>Images are made up of <a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Pixel#:~:text=In%20digital%20imaging%2C%20a%20pixel,can%20be%20manipulated%20through%20software\">pixels</a>, small units that represent the intensity or color at specific coordinates. Each pixel can be a single grayscale value or a tuple of values for color channels like RGB. In scientific computing and computer vision, images are typically stored as NumPy arrays: 2D arrays for grayscale images and 3D arrays (height \u00d7 width \u00d7 channels) for color images. This structured representation allows efficient numerical manipulation, making NumPy a powerful foundation for image processing, filtering, and machine learning applications.</p>", "a[href=\"#student-feedback\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Student Feedback<a class=\"headerlink\" href=\"#student-feedback\" title=\"Link to this heading\">#</a></h2><h3>Feedback welcome!<a class=\"headerlink\" href=\"#feedback-welcome\" title=\"Link to this heading\">#</a></h3><p>If you found this course website useful, please consider the following:</p>", "a[href=\"lectures/lecture-2-3.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">How is an image formed?<a class=\"headerlink\" href=\"#how-is-an-image-formed\" title=\"Link to this heading\">#</a></h1><p>In this lecture, we shall understand the Math and Geometry behind Image Formation. In the <a class=\"reference internal\" href=\"lectures/lecture-1.html\"><span class=\"std std-doc\">previous lecture</span></a>, we learned that images are stored/read as <code class=\"docutils literal notranslate\"><span class=\"pre\">numpy</span> <span class=\"pre\">arrays</span></code>. In this lecture we understand the way in which a 3D object is captured on a 2D image plane. In fact, we will see that a <code class=\"docutils literal notranslate\"><span class=\"pre\">camera</span> <span class=\"pre\">is</span> <span class=\"pre\">nothing</span> <span class=\"pre\">but</span> <span class=\"pre\">a</span> <span class=\"pre\">function</span> <span class=\"pre\">that</span> <span class=\"pre\">maps</span> <span class=\"pre\">a</span> <span class=\"pre\">3D</span> <span class=\"pre\">point</span> <span class=\"pre\">in</span> <span class=\"pre\">real-world</span> <span class=\"pre\">onto</span> <span class=\"pre\">a</span> <span class=\"pre\">2D</span> <span class=\"pre\">point</span> <span class=\"pre\">on</span> <span class=\"pre\">the</span> <span class=\"pre\">image</span> <span class=\"pre\">plane</span></code>.</p><p>Let\u2019s get started with an object that we want to capture. For this lecture, let\u2019s choose an object with regular shape.</p>", "a[href=\"website-features.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Website Features<a class=\"headerlink\" href=\"#website-features\" title=\"Link to this heading\">#</a></h1><p><strong>Welcome</strong> to the interactive side!</p><p>The Summer 2025 version of this course has been completely revamped on two key fundamentals:</p>", "a[href=\"lectures/lecture-17.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Conditional Diffusion Models<a class=\"headerlink\" href=\"#conditional-diffusion-models\" title=\"Link to this heading\">#</a></h1><h2>1. Conditional Diffusion Models<a class=\"headerlink\" href=\"#id1\" title=\"Link to this heading\">#</a></h2><p>Standard diffusion models sample from an unconditional distribution <span class=\"math notranslate nohighlight\">\\( p(\\mathbf{x}) \\)</span>.<br/>\nTo control the generation process, we condition on auxiliary information <span class=\"math notranslate nohighlight\">\\( \\mathbf{y} \\)</span> (e.g., class labels, text prompts, segmentation masks).</p><p>The conditional generative process is:</p>", "a[href=\"#feedback-welcome\"]": "<h3 class=\"tippy-header\" style=\"margin-top: 0;\">Feedback welcome!<a class=\"headerlink\" href=\"#feedback-welcome\" title=\"Link to this heading\">#</a></h3><p>If you found this course website useful, please consider the following:</p>", "a[href=\"lectures/lecture-10-11.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Computer Vision applications with Neural Networks<a class=\"headerlink\" href=\"#computer-vision-applications-with-neural-networks\" title=\"Link to this heading\">#</a></h1><p>In this section, we transition from classical vision techniques to modern <strong>data-driven learning</strong> methods: neural networks.</p><p>The core idea is simple: a neural network is a <strong>trainable function approximator</strong>. It can learn to represent very complex mappings by adjusting its internal parameters.</p>", "a[href=\"lectures/lecture-14.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Conditional VAEs, GANs and Conditional GANs<a class=\"headerlink\" href=\"#conditional-vaes-gans-and-conditional-gans\" title=\"Link to this heading\">#</a></h1><h2>1. Conditional Variational Autoencoders (CVAEs)<a class=\"headerlink\" href=\"#conditional-variational-autoencoders-cvaes\" title=\"Link to this heading\">#</a></h2><h3>1.1 Motivation<a class=\"headerlink\" href=\"#motivation\" title=\"Link to this heading\">#</a></h3><p>The standard VAE generates data from an unstructured latent space. But often we want <strong>controlled generation</strong> based on side information (e.g., labels, class, attributes).</p><p>This leads to <strong>Conditional VAEs</strong>, where generation is conditioned on <span class=\"math notranslate nohighlight\">\\( \\mathbf{y} \\)</span> (a label or auxiliary variable).</p>", "a[href=\"capstone-project.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Capstone Project Details and Deliverables<a class=\"headerlink\" href=\"#capstone-project-details-and-deliverables\" title=\"Link to this heading\">#</a></h1><p>CSE 4/573 is the <a class=\"reference external\" href=\"https://engineering.buffalo.edu/computer-science-engineering/graduate/degrees-and-programs/ms-in-computer-science-and-engineering/ms-tracks-and-specializations.html\">Capstone Course</a> at UB. The Capstone Project in this course brings concepts from across the degree into a single, semester-long group project.</p>", "a[href=\"#id1\"]": "<figure class=\"align-default\" id=\"id1\">\n<img alt=\"_images/course_pic2.jpeg\" src=\"_images/course_pic2.jpeg\"/>\n<figcaption>\n<p><span class=\"caption-number\">Fig. 1 </span><span class=\"caption-text\">In-class pictures with a few students (Students Enrolled: 71)</span><a class=\"headerlink\" href=\"#id1\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"lectures/lecture-13.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Feature Extractors for Generative Models<a class=\"headerlink\" href=\"#feature-extractors-for-generative-models\" title=\"Link to this heading\">#</a></h1><h2>1. Neural Networks as Feature Extractors<a class=\"headerlink\" href=\"#neural-networks-as-feature-extractors\" title=\"Link to this heading\">#</a></h2><p>A <strong>Neural Network (NN)</strong> can be decomposed into two conceptual parts:</p>", "a[href=\"course-schedule.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Course Schedule<a class=\"headerlink\" href=\"#course-schedule\" title=\"Link to this heading\">#</a></h1><p>This Computer Vision course runs from <strong>May 27 to August 14, 2025</strong>, meeting every Tuesday and Thursday. The curriculum progresses from fundamental concepts (image formation, processing) through core techniques (stereo vision, feature detection) to advanced topics (VAEs, diffusion models).</p><p>Key deliverables include:</p>", "a[href=\"lectures/lecture-15.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Diffusion Models<a class=\"headerlink\" href=\"#diffusion-models\" title=\"Link to this heading\">#</a></h1><h2>1. Motivation and Recap<a class=\"headerlink\" href=\"#motivation-and-recap\" title=\"Link to this heading\">#</a></h2><p><strong>Diffusion Models</strong> offer a new paradigm:</p>", "a[href=\"lectures/lecture-16.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Diffusion Model on Swiss Roll (DDPM) - PyTorch Code<a class=\"headerlink\" href=\"#diffusion-model-on-swiss-roll-ddpm-pytorch-code\" title=\"Link to this heading\">#</a></h1><p>In this notebook, we demonstrate a basic Diffusion Model training loop on a 2D Swiss Roll dataset.</p>", "a[href=\"#important-links\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Important Links<a class=\"headerlink\" href=\"#important-links\" title=\"Link to this heading\">#</a></h2>", "a[href=\"#cse-4-573-computer-vision-generative-ai\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">CSE 4/573: Computer Vision &amp; Generative AI<a class=\"headerlink\" href=\"#cse-4-573-computer-vision-generative-ai\" title=\"Link to this heading\">#</a></h1><h2>About the Course<a class=\"headerlink\" href=\"#about-the-course\" title=\"Link to this heading\">#</a></h2><p><strong>Overview:</strong><br/>\nA summer course that takes students from classical computer vision foundations all the way to modern generative models and practical systems.</p>", "a[href=\"lectures/lecture-12.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Intro to GenAI: What is a Data Distribution?<a class=\"headerlink\" href=\"#intro-to-genai-what-is-a-data-distribution\" title=\"Link to this heading\">#</a></h1><h2>Function Approximators<a class=\"headerlink\" href=\"#function-approximators\" title=\"Link to this heading\">#</a></h2><p>Neural networks are universal function approximators.<br/>\nThey learn to model an unknown function <span class=\"math notranslate nohighlight\">\\(y = f(x)\\)</span> by training on pairs of <span class=\"math notranslate nohighlight\">\\((x, y)\\)</span>.</p><p>Given data points:</p>", "a[href=\"#teaching-philosophy-and-approach\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Teaching Philosophy and Approach<a class=\"headerlink\" href=\"#teaching-philosophy-and-approach\" title=\"Link to this heading\">#</a></h2><p><strong>Overview:</strong><br/>\nMy teaching centers on intuition, curiosity, and frictionless experimentation through a fully interactive, browser-based ecosystem.</p>", "a[href=\"#instructor-and-course-mentors\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Instructor and Course Mentors<a class=\"headerlink\" href=\"#instructor-and-course-mentors\" title=\"Link to this heading\">#</a></h2>", "a[href=\"syllabus.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Course Syllabus<a class=\"headerlink\" href=\"#course-syllabus\" title=\"Link to this heading\">#</a></h1><h2>Course Information<a class=\"headerlink\" href=\"#course-information\" title=\"Link to this heading\">#</a></h2>", "a[href=\"lectures/lecture-6-7-8.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Depth Estimation using Stereo Vision<a class=\"headerlink\" href=\"#depth-estimation-using-stereo-vision\" title=\"Link to this heading\">#</a></h1><h2>What is Stereo Vision?<a class=\"headerlink\" href=\"#what-is-stereo-vision\" title=\"Link to this heading\">#</a></h2><p>Stereo vision is a <strong>classical computer vision technique</strong> that mimics human binocular vision to perceive depth. Just like your left and right eyes capture slightly different views of the world, two cameras placed at slightly different positions observe the same scene from different angles.</p>"}
skip_classes = ["headerlink", "sd-stretched-link"]

window.onload = function () {
    for (const [select, tip_html] of Object.entries(selector_to_html)) {
        const links = document.querySelectorAll(`main ${select}`);
        for (const link of links) {
            if (skip_classes.some(c => link.classList.contains(c))) {
                continue;
            }

            tippy(link, {
                content: tip_html,
                allowHTML: true,
                arrow: false,
                placement: 'auto-start', maxWidth: 500, interactive: true, boundary: document.body, appendTo: document.body,
                onShow(instance) {MathJax.typesetPromise([instance.popper]).then(() => {});},
            });
        };
    };
    console.log("tippy tips loaded!");
};
