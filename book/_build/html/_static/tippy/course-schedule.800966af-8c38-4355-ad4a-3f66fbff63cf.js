selector_to_html = {"a[href=\"lectures/lecture-15.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Diffusion Models<a class=\"headerlink\" href=\"#diffusion-models\" title=\"Link to this heading\">#</a></h1><h2>1. Motivation and Recap<a class=\"headerlink\" href=\"#motivation-and-recap\" title=\"Link to this heading\">#</a></h2><p><strong>Diffusion Models</strong> offer a new paradigm:</p>", "a[href=\"lectures/lecture-13.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Feature Extractors for Generative Models<a class=\"headerlink\" href=\"#feature-extractors-for-generative-models\" title=\"Link to this heading\">#</a></h1><h2>1. Neural Networks as Feature Extractors<a class=\"headerlink\" href=\"#neural-networks-as-feature-extractors\" title=\"Link to this heading\">#</a></h2><p>A <strong>Neural Network (NN)</strong> can be decomposed into two conceptual parts:</p>", "a[href=\"lectures/lecture-17.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Conditional Diffusion Models<a class=\"headerlink\" href=\"#conditional-diffusion-models\" title=\"Link to this heading\">#</a></h1><h2>1. Conditional Diffusion Models<a class=\"headerlink\" href=\"#id1\" title=\"Link to this heading\">#</a></h2><p>Standard diffusion models sample from an unconditional distribution <span class=\"math notranslate nohighlight\">\\( p(\\mathbf{x}) \\)</span>.<br/>\nTo control the generation process, we condition on auxiliary information <span class=\"math notranslate nohighlight\">\\( \\mathbf{y} \\)</span> (e.g., class labels, text prompts, segmentation masks).</p><p>The conditional generative process is:</p>", "a[href=\"#submission-policies\"]": "<h3 class=\"tippy-header\" style=\"margin-top: 0;\">\u26a0\ufe0f Submission Policies<a class=\"headerlink\" href=\"#submission-policies\" title=\"Link to this heading\">#</a></h3>", "a[href=\"lectures/lecture-1.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">What is a Pixel and what is an Image?<a class=\"headerlink\" href=\"#what-is-a-pixel-and-what-is-an-image\" title=\"Link to this heading\">#</a></h1><p>Images are made up of <a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Pixel#:~:text=In%20digital%20imaging%2C%20a%20pixel,can%20be%20manipulated%20through%20software\">pixels</a>, small units that represent the intensity or color at specific coordinates. Each pixel can be a single grayscale value or a tuple of values for color channels like RGB. In scientific computing and computer vision, images are typically stored as NumPy arrays: 2D arrays for grayscale images and 3D arrays (height \u00d7 width \u00d7 channels) for color images. This structured representation allows efficient numerical manipulation, making NumPy a powerful foundation for image processing, filtering, and machine learning applications.</p>", "a[href=\"#exams-45\"]": "<h3 class=\"tippy-header\" style=\"margin-top: 0;\">\ud83d\udcda Exams (45%)<a class=\"headerlink\" href=\"#exams-45\" title=\"Link to this heading\">#</a></h3><p><strong>Exam Features</strong>:</p>", "a[href=\"#quizzes-20\"]": "<h3 class=\"tippy-header\" style=\"margin-top: 0;\">\u2714\ufe0f Quizzes (20%)<a class=\"headerlink\" href=\"#quizzes-20\" title=\"Link to this heading\">#</a></h3><p><strong>Format</strong>:</p>", "a[href=\"#capstone-project-20\"]": "<h3 class=\"tippy-header\" style=\"margin-top: 0;\">\ud83c\udfc6 Capstone Project (20%)<a class=\"headerlink\" href=\"#capstone-project-20\" title=\"Link to this heading\">#</a></h3>", "a[href=\"lectures/lecture-2-3.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">How is an image formed?<a class=\"headerlink\" href=\"#how-is-an-image-formed\" title=\"Link to this heading\">#</a></h1><p>In this lecture, we shall understand the Math and Geometry behind Image Formation. In the <a class=\"reference internal\" href=\"lectures/lecture-1.html\"><span class=\"std std-doc\">previous lecture</span></a>, we learned that images are stored/read as <code class=\"docutils literal notranslate\"><span class=\"pre\">numpy</span> <span class=\"pre\">arrays</span></code>. In this lecture we understand the way in which a 3D object is captured on a 2D image plane. In fact, we will see that a <code class=\"docutils literal notranslate\"><span class=\"pre\">camera</span> <span class=\"pre\">is</span> <span class=\"pre\">nothing</span> <span class=\"pre\">but</span> <span class=\"pre\">a</span> <span class=\"pre\">function</span> <span class=\"pre\">that</span> <span class=\"pre\">maps</span> <span class=\"pre\">a</span> <span class=\"pre\">3D</span> <span class=\"pre\">point</span> <span class=\"pre\">in</span> <span class=\"pre\">real-world</span> <span class=\"pre\">onto</span> <span class=\"pre\">a</span> <span class=\"pre\">2D</span> <span class=\"pre\">point</span> <span class=\"pre\">on</span> <span class=\"pre\">the</span> <span class=\"pre\">image</span> <span class=\"pre\">plane</span></code>.</p><p>Let\u2019s get started with an object that we want to capture. For this lecture, let\u2019s choose an object with regular shape.</p>", "a[href=\"lectures/lecture-9.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Feature Detection and Extraction<a class=\"headerlink\" href=\"#feature-detection-and-extraction\" title=\"Link to this heading\">#</a></h1><p>In this chapter, we move from <strong>depth estimation</strong> to one of the core tasks in classical computer vision: <strong>finding good feature points</strong>.</p>", "a[href=\"#course-deliverables-breakdown\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Course Deliverables Breakdown<a class=\"headerlink\" href=\"#course-deliverables-breakdown\" title=\"Link to this heading\">#</a></h2><h3>\ud83d\udcdd Programming Assignment (10%)<a class=\"headerlink\" href=\"#programming-assignment-10\" title=\"Link to this heading\">#</a></h3>", "a[href=\"lectures/lecture-6-7-8.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Depth Estimation using Stereo Vision<a class=\"headerlink\" href=\"#depth-estimation-using-stereo-vision\" title=\"Link to this heading\">#</a></h1><h2>What is Stereo Vision?<a class=\"headerlink\" href=\"#what-is-stereo-vision\" title=\"Link to this heading\">#</a></h2><p>Stereo vision is a <strong>classical computer vision technique</strong> that mimics human binocular vision to perceive depth. Just like your left and right eyes capture slightly different views of the world, two cameras placed at slightly different positions observe the same scene from different angles.</p>", "a[href=\"lectures/lecture-4.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Image Processing (Part 1) Spatial Domain<a class=\"headerlink\" href=\"#image-processing-part-1-spatial-domain\" title=\"Link to this heading\">#</a></h1><p>As we established multiple times in this course that images are nothing but <code class=\"docutils literal notranslate\"><span class=\"pre\">numpy</span> <span class=\"pre\">arrays</span></code> where each value in the grid represents a pixel. In the case of a grayscale image, the pixel represents intensity from <code class=\"docutils literal notranslate\"><span class=\"pre\">0</span> <span class=\"pre\">to</span> <span class=\"pre\">255</span></code> and in the case of a colored RGB image, each pixel is a vector <code class=\"docutils literal notranslate\"><span class=\"pre\">[R,</span> <span class=\"pre\">G,</span> <span class=\"pre\">B]</span></code> values ranging from 0 to 255. Depending on different combinations of R, G, and B, we can visualize different colors at each pixel.</p><p><em>In this lecture, we will look at various image processing techniques that will result in extraction of various features from images.</em></p>", "a[href=\"lectures/lecture-14.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Conditional VAEs, GANs and Conditional GANs<a class=\"headerlink\" href=\"#conditional-vaes-gans-and-conditional-gans\" title=\"Link to this heading\">#</a></h1><h2>1. Conditional Variational Autoencoders (CVAEs)<a class=\"headerlink\" href=\"#conditional-variational-autoencoders-cvaes\" title=\"Link to this heading\">#</a></h2><h3>1.1 Motivation<a class=\"headerlink\" href=\"#motivation\" title=\"Link to this heading\">#</a></h3><p>The standard VAE generates data from an unstructured latent space. But often we want <strong>controlled generation</strong> based on side information (e.g., labels, class, attributes).</p><p>This leads to <strong>Conditional VAEs</strong>, where generation is conditioned on <span class=\"math notranslate nohighlight\">\\( \\mathbf{y} \\)</span> (a label or auxiliary variable).</p>", "a[href=\"lectures/lecture-16.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Diffusion Model on Swiss Roll (DDPM) - PyTorch Code<a class=\"headerlink\" href=\"#diffusion-model-on-swiss-roll-ddpm-pytorch-code\" title=\"Link to this heading\">#</a></h1><p>In this notebook, we demonstrate a basic Diffusion Model training loop on a 2D Swiss Roll dataset.</p>", "a[href=\"#programming-assignment-10\"]": "<h3 class=\"tippy-header\" style=\"margin-top: 0;\">\ud83d\udcdd Programming Assignment (10%)<a class=\"headerlink\" href=\"#programming-assignment-10\" title=\"Link to this heading\">#</a></h3>", "a[href=\"syllabus.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Course Syllabus<a class=\"headerlink\" href=\"#course-syllabus\" title=\"Link to this heading\">#</a></h1><h2>Course Information<a class=\"headerlink\" href=\"#course-information\" title=\"Link to this heading\">#</a></h2>", "a[href=\"lectures/lecture-10-11.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Computer Vision applications with Neural Networks<a class=\"headerlink\" href=\"#computer-vision-applications-with-neural-networks\" title=\"Link to this heading\">#</a></h1><p>In this section, we transition from classical vision techniques to modern <strong>data-driven learning</strong> methods: neural networks.</p><p>The core idea is simple: a neural network is a <strong>trainable function approximator</strong>. It can learn to represent very complex mappings by adjusting its internal parameters.</p>", "a[href=\"lectures/lecture-5.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Image Processing (Part 2) Fourier Domain<a class=\"headerlink\" href=\"#image-processing-part-2-fourier-domain\" title=\"Link to this heading\">#</a></h1><h2>What is a Function in the Time Domain?<a class=\"headerlink\" href=\"#what-is-a-function-in-the-time-domain\" title=\"Link to this heading\">#</a></h2><p><strong>Mathematically:</strong><br/>\n<span class=\"math notranslate nohighlight\">\\( f(t): \\mathbb{R} \\to \\mathbb{R} \\)</span> \u2014 maps time to amplitude.</p>", "a[href=\"lectures/lecture-12.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Intro to GenAI: What is a Data Distribution?<a class=\"headerlink\" href=\"#intro-to-genai-what-is-a-data-distribution\" title=\"Link to this heading\">#</a></h1><h2>Function Approximators<a class=\"headerlink\" href=\"#function-approximators\" title=\"Link to this heading\">#</a></h2><p>Neural networks are universal function approximators.<br/>\nThey learn to model an unknown function <span class=\"math notranslate nohighlight\">\\(y = f(x)\\)</span> by training on pairs of <span class=\"math notranslate nohighlight\">\\((x, y)\\)</span>.</p><p>Given data points:</p>", "a[href=\"#lecture-dates-and-details-2025\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Lecture Dates and Details (2025)<a class=\"headerlink\" href=\"#lecture-dates-and-details-2025\" title=\"Link to this heading\">#</a></h2>", "a[href=\"#course-schedule\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Course Schedule<a class=\"headerlink\" href=\"#course-schedule\" title=\"Link to this heading\">#</a></h1><p>This Computer Vision course runs from <strong>May 27 to August 14, 2025</strong>, meeting every Tuesday and Thursday. The curriculum progresses from fundamental concepts (image formation, processing) through core techniques (stereo vision, feature detection) to advanced topics (VAEs, diffusion models).</p><p>Key deliverables include:</p>"}
skip_classes = ["headerlink", "sd-stretched-link"]

window.onload = function () {
    for (const [select, tip_html] of Object.entries(selector_to_html)) {
        const links = document.querySelectorAll(`main ${select}`);
        for (const link of links) {
            if (skip_classes.some(c => link.classList.contains(c))) {
                continue;
            }

            tippy(link, {
                content: tip_html,
                allowHTML: true,
                arrow: false,
                placement: 'auto-start', maxWidth: 500, interactive: true, boundary: document.body, appendTo: document.body,
                onShow(instance) {MathJax.typesetPromise([instance.popper]).then(() => {});},
            });
        };
    };
    console.log("tippy tips loaded!");
};
