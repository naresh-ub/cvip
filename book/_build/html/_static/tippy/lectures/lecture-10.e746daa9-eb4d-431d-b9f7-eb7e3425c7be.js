selector_to_html = {"a[href=\"#the-problem-with-raw-pixels\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">The Problem with Raw Pixels<a class=\"headerlink\" href=\"#the-problem-with-raw-pixels\" title=\"Link to this heading\">#</a></h2><p>A fully connected neural network takes all input pixels, flattens them into a <strong>1D vector</strong>, and tries to find patterns by learning weights for each pixel independently.</p><p>This works for very simple data \u2014 but:</p>", "a[href=\"#what-is-segmentation\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">What is Segmentation?<a class=\"headerlink\" href=\"#what-is-segmentation\" title=\"Link to this heading\">#</a></h2><p>In <strong>semantic segmentation</strong>, our goal is to assign a <strong>class label to each pixel</strong> of an input image.</p><p>Example:</p>", "a[href=\"#mathematical-formulation\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Mathematical Formulation<a class=\"headerlink\" href=\"#mathematical-formulation\" title=\"Link to this heading\">#</a></h2><p><strong>Model</strong>:</p>", "a[href=\"#universal-approximation-theorem\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Universal Approximation Theorem<a class=\"headerlink\" href=\"#universal-approximation-theorem\" title=\"Link to this heading\">#</a></h2><p>Mathematically, it can be shown that a feed-forward neural network with at least one hidden layer and nonlinear activation can approximate any continuous function on compact subsets of <span class=\"math notranslate nohighlight\">\\(\\mathbb{R}^n\\)</span> to arbitrary precision, given enough hidden units.</p><p>This result is called the <strong>Universal Approximation Theorem</strong>.</p>", "a[href=\"#multi-dimensional-inputs-and-decision-boundaries\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Multi-dimensional Inputs and Decision Boundaries<a class=\"headerlink\" href=\"#multi-dimensional-inputs-and-decision-boundaries\" title=\"Link to this heading\">#</a></h1><p>Before we classify images, we must understand how a neural network handles <strong>multi-dimensional input vectors</strong>.</p>", "a[href=\"#adding-convolution-to-a-neural-network\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Adding Convolution to a Neural Network<a class=\"headerlink\" href=\"#adding-convolution-to-a-neural-network\" title=\"Link to this heading\">#</a></h2><p>By adding <strong>just one convolutional layer</strong> before the dense layers:</p>", "a[href=\"#visualizing-feature-maps-in-a-convolutional-layer\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Visualizing Feature Maps in a Convolutional Layer<a class=\"headerlink\" href=\"#visualizing-feature-maps-in-a-convolutional-layer\" title=\"Link to this heading\">#</a></h1><p>A <strong>convolutional layer</strong> learns <strong>local patterns</strong> by sliding small filters across the input image.</p><p>These filters produce <strong>feature maps</strong>:</p>", "a[href=\"#common-detection-loss-multi-task-loss\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Common Detection Loss: Multi-Task Loss<a class=\"headerlink\" href=\"#common-detection-loss-multi-task-loss\" title=\"Link to this heading\">#</a></h2><p>This <strong>multi-task loss</strong> ensures the model learns <strong>where</strong> and <strong>what</strong> simultaneously.</p>", "a[href=\"#loss-function-pixel-wise-cross-entropy\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Loss Function: Pixel-wise Cross-Entropy<a class=\"headerlink\" href=\"#loss-function-pixel-wise-cross-entropy\" title=\"Link to this heading\">#</a></h2><p>The <strong>loss</strong> compares the predicted class probability for every pixel to the true class.</p>", "a[href=\"#what-is-depth-estimation\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">What is Depth Estimation?<a class=\"headerlink\" href=\"#what-is-depth-estimation\" title=\"Link to this heading\">#</a></h2><p>Depth estimation predicts the <strong>distance</strong> of each pixel in an image to the camera.<br/>\nIt turns a single RGB image into a dense <strong>depth map</strong>.</p><p>Example:</p>", "a[href=\"#computer-vision-applications-with-neural-networks\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Computer Vision applications with Neural Networks<a class=\"headerlink\" href=\"#computer-vision-applications-with-neural-networks\" title=\"Link to this heading\">#</a></h1><p>In this section, we transition from classical vision techniques to modern <strong>data-driven learning</strong> methods: neural networks.</p><p>The core idea is simple: a neural network is a <strong>trainable function approximator</strong>. It can learn to represent very complex mappings by adjusting its internal parameters.</p>", "a[href=\"#how-to-use-pixels\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">How to Use Pixels?<a class=\"headerlink\" href=\"#how-to-use-pixels\" title=\"Link to this heading\">#</a></h2><p>We can treat the pixel values directly as input features.</p><p>For example:</p>", "a[href=\"#what-we-will-do\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">What We Will Do<a class=\"headerlink\" href=\"#what-we-will-do\" title=\"Link to this heading\">#</a></h2><p>In this notebook, we will:</p>", "a[href=\"#what-is-a-multi-dimensional-input\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">What is a Multi-dimensional Input?<a class=\"headerlink\" href=\"#what-is-a-multi-dimensional-input\" title=\"Link to this heading\">#</a></h2><p>In 1D, the input <span class=\"math notranslate nohighlight\">\\(x\\)</span> is a single number.<br/>\nIn 2D or 3D, the input is a <strong>vector</strong>:</p>", "a[href=\"#why-input-output-and-loss-function-are-everything\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Why Input, Output, and Loss Function Are Everything<a class=\"headerlink\" href=\"#why-input-output-and-loss-function-are-everything\" title=\"Link to this heading\">#</a></h1><p>When building <strong>deep learning models</strong>, the architecture (layers, neurons, activation functions) often gets the spotlight. But at a deeper level, the real <strong>heart</strong> of any deep learning system is this:</p><p><strong>How you format the input</strong><br/>\n<strong>What you expect as output</strong><br/>\n<strong>How you define the loss function to compare output to the ground truth</strong></p>", "a[href=\"#example-binary-classification-in-2d\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Example: Binary Classification in 2D<a class=\"headerlink\" href=\"#example-binary-classification-in-2d\" title=\"Link to this heading\">#</a></h2><p>Suppose we want to classify whether a point belongs to <strong>class 0</strong> or <strong>class 1</strong> based on its coordinates <span class=\"math notranslate nohighlight\">\\((x_1, x_2)\\)</span>.</p><p>A simple model:</p>", "a[href=\"#how-does-a-neural-network-learn\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">How Does a Neural Network Learn?<a class=\"headerlink\" href=\"#how-does-a-neural-network-learn\" title=\"Link to this heading\">#</a></h2><p>A neural network learns by minimizing a <strong>loss function</strong> <span class=\"math notranslate nohighlight\">\\(L\\)</span>. The loss function measures how far the predicted outputs <span class=\"math notranslate nohighlight\">\\(\\hat{y}\\)</span> are from the true targets <span class=\"math notranslate nohighlight\">\\(y\\)</span>.</p><p>One common choice for regression is <strong>Mean Squared Error (MSE)</strong>:</p>", "a[href=\"#why-this-matters\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Why This Matters<a class=\"headerlink\" href=\"#why-this-matters\" title=\"Link to this heading\">#</a></h2><p>The <strong>output format</strong> is not just a single label, but a dense grid.\nSo the architecture must:</p>", "a[href=\"#the-universal-pattern\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">The Universal Pattern<a class=\"headerlink\" href=\"#the-universal-pattern\" title=\"Link to this heading\">#</a></h2><p>Every deep learning task follows this logic:</p><p><strong>Input</strong>: Data format<br/>\n<strong>Model</strong>: A function <span class=\"math notranslate nohighlight\">\\(f(x; \\theta)\\)</span> parameterized by weights <span class=\"math notranslate nohighlight\">\\(\\theta\\)</span><br/>\n<strong>Output</strong>: Prediction <span class=\"math notranslate nohighlight\">\\(\\hat{y} = f(x; \\theta)\\)</span><br/>\n<strong>Loss</strong>: <span class=\"math notranslate nohighlight\">\\(L(\\hat{y}, y)\\)</span>, the cost of being wrong</p>", "a[href=\"#output-layer-softmax\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Output Layer &amp; Softmax<a class=\"headerlink\" href=\"#output-layer-softmax\" title=\"Link to this heading\">#</a></h2><p>For <strong>multi-class classification</strong>, the output must represent a valid probability distribution over classes.</p><p>We use <strong>softmax</strong>:</p>", "a[href=\"#semantic-image-segmentation-input-output-and-loss\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Semantic Image Segmentation: Input, Output, and Loss<a class=\"headerlink\" href=\"#semantic-image-segmentation-input-output-and-loss\" title=\"Link to this heading\">#</a></h1><h2>What is Segmentation?<a class=\"headerlink\" href=\"#what-is-segmentation\" title=\"Link to this heading\">#</a></h2><p>In <strong>semantic segmentation</strong>, our goal is to assign a <strong>class label to each pixel</strong> of an input image.</p><p>Example:</p>", "a[href=\"#key-difference\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Key Difference<a class=\"headerlink\" href=\"#key-difference\" title=\"Link to this heading\">#</a></h2><p>Below is a working Hugging Face + PyTorch example.</p>", "a[href=\"#example-using-a-pretrained-segmentation-model-hugging-face\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Example: Using a Pretrained Segmentation Model (Hugging Face)<a class=\"headerlink\" href=\"#example-using-a-pretrained-segmentation-model-hugging-face\" title=\"Link to this heading\">#</a></h2><p>Below, we\u2019ll see this using a pretrained <strong>DeepLabV3</strong> model.<br/>\nYou\u2019ll see how:</p>", "a[href=\"#why-use-neural-networks\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Why Use Neural Networks?<a class=\"headerlink\" href=\"#why-use-neural-networks\" title=\"Link to this heading\">#</a></h2><p>Neural networks can learn to approximate highly complex, nonlinear functions. They do this by combining <strong>simple linear transformations</strong> with <strong>nonlinear activation functions</strong>.</p>", "a[href=\"#why-use-activation-functions\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Why Use Activation Functions?<a class=\"headerlink\" href=\"#why-use-activation-functions\" title=\"Link to this heading\">#</a></h2><p>A layer without activation is just a linear mapping:</p>", "a[href=\"#important-considerations\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Important Considerations<a class=\"headerlink\" href=\"#important-considerations\" title=\"Link to this heading\">#</a></h2><p>Later, we will see how <strong>CNNs</strong> improve by using local patterns.</p>", "a[href=\"#what-changes-here\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">What changes here?<a class=\"headerlink\" href=\"#what-changes-here\" title=\"Link to this heading\">#</a></h2><p>Unlike segmentation:</p>", "a[href=\"#typical-input-output-for-segmentation\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Typical Input/Output for Segmentation<a class=\"headerlink\" href=\"#typical-input-output-for-segmentation\" title=\"Link to this heading\">#</a></h2>", "a[href=\"#basic-processing-steps\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Basic Processing Steps<a class=\"headerlink\" href=\"#basic-processing-steps\" title=\"Link to this heading\">#</a></h2>", "a[href=\"#why-use-images\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Why Use Images?<a class=\"headerlink\" href=\"#why-use-images\" title=\"Link to this heading\">#</a></h2><p>In computer vision, the input <span class=\"math notranslate nohighlight\">\\(x\\)</span> is no longer a single number or vector of features but an <strong>image</strong>.</p><p>An image is a matrix (or tensor for RGB):</p>", "a[href=\"#example-hugging-face-pre-trained-detector\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Example: Hugging Face Pre-trained Detector<a class=\"headerlink\" href=\"#example-hugging-face-pre-trained-detector\" title=\"Link to this heading\">#</a></h2><p>Below, we\u2019ll run an example with an existing <strong>object detection model</strong> (like DETR or YOLOv8) from Hugging Face Transformers \u2014 so you can see how the input, output, and loss align <strong>in practice</strong>.</p>", "a[href=\"#neural-networks-learn-these-boundaries\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Neural Networks Learn These Boundaries<a class=\"headerlink\" href=\"#neural-networks-learn-these-boundaries\" title=\"Link to this heading\">#</a></h2><p>A neural network adjusts its weights to position this line (or plane) to best separate the data points into classes.</p>", "a[href=\"#workflow\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Workflow<a class=\"headerlink\" href=\"#workflow\" title=\"Link to this heading\">#</a></h2><p><strong>Input Image</strong> \u2192 <strong>Flatten</strong> \u2192 <strong>Fully Connected Layers</strong> \u2192 <strong>Softmax</strong> \u2192 <strong>Class Probabilities</strong></p>", "a[href=\"#what-is-a-function\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">What is a Function?<a class=\"headerlink\" href=\"#what-is-a-function\" title=\"Link to this heading\">#</a></h2><p>A function is a rule that maps an input <span class=\"math notranslate nohighlight\">\\(x\\)</span> to an output <span class=\"math notranslate nohighlight\">\\(y\\)</span>:</p>", "a[href=\"#the-power-of-features\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">The Power of Features<a class=\"headerlink\" href=\"#the-power-of-features\" title=\"Link to this heading\">#</a></h2><p>What if we <strong>extract useful local features first</strong>?</p><p>For images:</p>", "a[href=\"#image-classification-with-fully-connected-neural-networks\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Image Classification with Fully Connected Neural Networks<a class=\"headerlink\" href=\"#image-classification-with-fully-connected-neural-networks\" title=\"Link to this heading\">#</a></h1><h2>Why Use Images?<a class=\"headerlink\" href=\"#why-use-images\" title=\"Link to this heading\">#</a></h2><p>In computer vision, the input <span class=\"math notranslate nohighlight\">\\(x\\)</span> is no longer a single number or vector of features but an <strong>image</strong>.</p><p>An image is a matrix (or tensor for RGB):</p>", "a[href=\"#how-this-changes-the-problem\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">How This Changes the Problem<a class=\"headerlink\" href=\"#how-this-changes-the-problem\" title=\"Link to this heading\">#</a></h2><p>Unlike image classification (one label for whole image) or object detection (boxes + labels), segmentation requires:</p>", "a[href=\"#loss-function-cross-entropy\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Loss Function: Cross-Entropy<a class=\"headerlink\" href=\"#loss-function-cross-entropy\" title=\"Link to this heading\">#</a></h2><p>To train the network, we compare predicted probabilities with the true labels using <strong>categorical cross-entropy</strong>:</p>", "a[href=\"#loss-function\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Loss Function<a class=\"headerlink\" href=\"#loss-function\" title=\"Link to this heading\">#</a></h2><p>The most common is the <strong>Mean Squared Error (MSE)</strong>:</p>", "a[href=\"#gradient-descent\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Gradient Descent<a class=\"headerlink\" href=\"#gradient-descent\" title=\"Link to this heading\">#</a></h2><p>To minimize the loss, we use <strong>gradient descent</strong>. We compute the partial derivatives of <span class=\"math notranslate nohighlight\">\\(L\\)</span> with respect to each parameter.</p><p>Then, we update each parameter in the direction that reduces the loss:</p>", "a[href=\"#monocular-depth-estimation\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Monocular Depth Estimation<a class=\"headerlink\" href=\"#monocular-depth-estimation\" title=\"Link to this heading\">#</a></h1><h2>What is Depth Estimation?<a class=\"headerlink\" href=\"#what-is-depth-estimation\" title=\"Link to this heading\">#</a></h2><p>Depth estimation predicts the <strong>distance</strong> of each pixel in an image to the camera.<br/>\nIt turns a single RGB image into a dense <strong>depth map</strong>.</p><p>Example:</p>", "a[href=\"#interpretation\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Interpretation<a class=\"headerlink\" href=\"#interpretation\" title=\"Link to this heading\">#</a></h2><p>In this example:</p>", "a[href=\"#input-output-shapes\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Input/Output Shapes<a class=\"headerlink\" href=\"#input-output-shapes\" title=\"Link to this heading\">#</a></h2>", "a[href=\"#why-the-loss-function-defines-the-problem\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Why the Loss Function Defines the Problem<a class=\"headerlink\" href=\"#why-the-loss-function-defines-the-problem\" title=\"Link to this heading\">#</a></h2><p>A <strong>loss function</strong> is a precise mathematical contract:</p>", "a[href=\"#why-do-convolutional-neural-networks-cnns-improve-image-classification\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\">Why Do Convolutional Neural Networks (CNNs) Improve Image Classification?<a class=\"headerlink\" href=\"#why-do-convolutional-neural-networks-cnns-improve-image-classification\" title=\"Link to this heading\">#</a></h1><h2>The Problem with Raw Pixels<a class=\"headerlink\" href=\"#the-problem-with-raw-pixels\" title=\"Link to this heading\">#</a></h2><p>A fully connected neural network takes all input pixels, flattens them into a <strong>1D vector</strong>, and tries to find patterns by learning weights for each pixel independently.</p><p>This works for very simple data \u2014 but:</p>", "a[href=\"#how-a-convolutional-layer-works\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">How a Convolutional Layer Works<a class=\"headerlink\" href=\"#how-a-convolutional-layer-works\" title=\"Link to this heading\">#</a></h2><p>A convolutional layer:</p>", "a[href=\"#example-object-detection\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\">Example: Object Detection<a class=\"headerlink\" href=\"#example-object-detection\" title=\"Link to this heading\">#</a></h2><p>Let\u2019s break it down:</p>"}
skip_classes = ["headerlink", "sd-stretched-link"]

window.onload = function () {
    for (const [select, tip_html] of Object.entries(selector_to_html)) {
        const links = document.querySelectorAll(`main ${select}`);
        for (const link of links) {
            if (skip_classes.some(c => link.classList.contains(c))) {
                continue;
            }

            tippy(link, {
                content: tip_html,
                allowHTML: true,
                arrow: false,
                placement: 'auto-start', maxWidth: 500, interactive: true, boundary: document.body, appendTo: document.body,
                onShow(instance) {MathJax.typesetPromise([instance.popper]).then(() => {});},
            });
        };
    };
    console.log("tippy tips loaded!");
};
